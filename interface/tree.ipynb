{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelib import Node, Tree\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span\n",
    "import pandas as pd\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I want a red car with heated seats.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I want a blue car with CarPlay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I want an old and cheap car with emission volu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I want an expensive car with all configurations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I want a black car with navigation system and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  0                I want a red car with heated seats.\n",
       "1  1                    I want a blue car with CarPlay.\n",
       "2  2  I want an old and cheap car with emission volu...\n",
       "3  3   I want an expensive car with all configurations.\n",
       "4  4  I want a black car with navigation system and ..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df = pd.read_csv(\"../queries/query_20.tsv\", sep=\"\\t\", header=None)\n",
    "getq = lambda i: queries_df.loc[i, 1]\n",
    "queries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "from spacy.util import compile_infix_regex\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    inf = list(nlp.Defaults.infixes)               # Default infixes\n",
    "    inf.remove(r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\")    # Remove the generic op between numbers or between a number and a -\n",
    "    inf = tuple(inf)                               # Convert inf to tuple\n",
    "    infixes = inf + tuple([r\"(?<=[0-9])[+*^](?=[0-9-])\", r\"(?<=[0-9])-(?=-)\"])  # Add the removed rule after subtracting (?<=[0-9])-(?=[0-9]) pattern\n",
    "    infixes = [x for x in infixes if '-|–|—|--|---|——|~' not in x] # Remove - between letters rule\n",
    "    infix_re = compile_infix_regex(infixes)\n",
    "\n",
    "    return Tokenizer(nlp.vocab, prefix_search=nlp.tokenizer.prefix_search,\n",
    "                                suffix_search=nlp.tokenizer.suffix_search,\n",
    "                                infix_finditer=infix_re.finditer,\n",
    "                                token_match=nlp.tokenizer.token_match,\n",
    "                                rules=nlp.Defaults.tokenizer_exceptions)\n",
    "    \n",
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.dep_matcher = DependencyMatcher(vocab=nlp.vocab)\n",
    "        main_patterns = [\n",
    "                # [\n",
    "                #     {'RIGHT_ID': 'p_subject', 'RIGHT_ATTRS': {'TEXT': 'car', 'DEP': 'dobj'}},\n",
    "                #     {'LEFT_ID': 'p_subject', 'REL_OP': '>', 'RIGHT_ID': 'p_prep_to_subject', 'RIGHT_ATTRS': {'DEP': 'prep'}},\n",
    "                #     {'LEFT_ID': 'p_prep_to_subject', 'REL_OP': '>', 'RIGHT_ID': 'p_prep_object', 'RIGHT_ATTRS': {'DEP': {\"REGEX\": \"\\s*\"}}}\n",
    "                # ],\n",
    "                [\n",
    "                {'RIGHT_ID': 'p_object', 'RIGHT_ATTRS': {'DEP': {\"IN\": ['dobj', 'pobj']}}},\n",
    "                {'LEFT_ID': 'p_object', 'REL_OP': '>', 'RIGHT_ID': 'p_object_mod', 'RIGHT_ATTRS': {'DEP': 'amod'}},\n",
    "                ]\n",
    "            ] # TODO: CONFIG HERE\n",
    "        self.dep_matcher.add(f\"main_patterns\", patterns=main_patterns)\n",
    "    \n",
    "    @staticmethod\n",
    "    def traverse(s, tree):\n",
    "        for c in s.children:\n",
    "            tree.create_node(c, c,  parent=s, data=c)\n",
    "            tree = FeatureExtractor.traverse(c, tree=tree)\n",
    "        return tree\n",
    "    \n",
    "    @staticmethod   \n",
    "    def build_tree(query):\n",
    "        doc = nlp(query)\n",
    "        sent_tree = Tree()\n",
    "        s = list(doc.sents)[0].root\n",
    "        sent_tree.create_node(s, s, data=s)\n",
    "        sent_tree = FeatureExtractor.traverse(s, sent_tree)\n",
    "        return sent_tree\n",
    "    \n",
    "    @staticmethod  \n",
    "    def build_tree_from_node(node):\n",
    "        sent_tree = Tree()\n",
    "        sent_tree.create_node(node, node, data=node)\n",
    "        sent_tree = FeatureExtractor.traverse(node, sent_tree)\n",
    "        return sent_tree\n",
    "    \n",
    "    @staticmethod\n",
    "    def compile_secondary_patterns(main_subject=\"\"):\n",
    "        secondary_patterns = [\n",
    "            [\n",
    "                {'RIGHT_ID': 'p_object', 'RIGHT_ATTRS': {'DEP': {\"IN\": ['dobj', 'pobj']}}},\n",
    "                {'LEFT_ID': 'p_object', 'REL_OP': '>', 'RIGHT_ID': 'p_object_mod', 'RIGHT_ATTRS': {'DEP': {\"IN\": ['amod', 'compound']}}},\n",
    "            ],\n",
    "            [\n",
    "                {'RIGHT_ID': 'p_conj', 'RIGHT_ATTRS': {'DEP': 'conj'}},\n",
    "                {'LEFT_ID': 'p_conj', 'REL_OP': '>', 'RIGHT_ID': 'p_conj_mod', 'RIGHT_ATTRS': {'DEP': {\"IN\": ['amod', 'advmod']}}},\n",
    "            ]\n",
    "        ]\n",
    "        return secondary_patterns\n",
    "    \n",
    "    def extract(self, query):\n",
    "        nlp.tokenizer = custom_tokenizer(nlp)\n",
    "        doc = nlp(query)\n",
    "        # dep_matches = self.dep_matcher(doc)\n",
    "        # for match in dep_matches:\n",
    "        #     matches = match[1]\n",
    "        #     p_subject, p_prep_to_subject, p_prep_object = matches[0], matches[1], matches[2]\n",
    "        #     print(f\"{doc}\\n\\t{doc[p_subject]}: {doc[p_prep_object]}\")\n",
    "        #     for s in doc.sents:\n",
    "        #         st0 = FeatureExtractor.build_tree_from_node(s.root)\n",
    "        #         st0.show(data_property=[\"text\", \"dep_\"])\n",
    "        secondary_matcher = DependencyMatcher(vocab=nlp.vocab)\n",
    "        secondary_matcher.add(\"secondary_patterns\", FeatureExtractor.compile_secondary_patterns())\n",
    "        dep_matches = secondary_matcher(doc)\n",
    "        print(f\"{doc}\")\n",
    "        for match in dep_matches:\n",
    "            matches = match[1]\n",
    "            p_1, p_2 = matches[0], matches[1]\n",
    "            print(f\"\\t-> {doc[p_1]} {doc[p_2]}\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want a red car with heated seats.\n",
      "\t-> car red\n",
      "\t-> seats heated\n"
     ]
    }
   ],
   "source": [
    "fe.extract(\"I want a red car with heated seats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want a red SUV with heated seats.\n",
      "\t-> SUV red\n",
      "\t-> seats heated\n"
     ]
    }
   ],
   "source": [
    "fe.extract(\"I want a red SUV with heated seats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want a black car with wind shield.\n",
      "\t-> car black\n",
      "\t-> shield wind\n"
     ]
    }
   ],
   "source": [
    "fe.extract(\"I want a black car with wind shield.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract 0\n",
      "I want a red car with heated seats.\n",
      "\t-> car red\n",
      "\t-> seats heated\n",
      "extract 1\n",
      "I want a blue car with CarPlay.\n",
      "\t-> car blue\n",
      "extract 2\n",
      "I want an old and cheap car with emission volume of 3.0.\n",
      "\t-> car old\n",
      "\t-> volume emission\n",
      "extract 3\n",
      "I want an expensive car with all configurations.\n",
      "\t-> car expensive\n",
      "extract 4\n",
      "I want a black car with navigation system and moderate price.\n",
      "\t-> car black\n",
      "\t-> system navigation\n",
      "\t-> price moderate\n",
      "extract 5\n",
      "I want a car with high performance.\n",
      "\t-> performance high\n",
      "extract 6\n",
      "I want a Tesla electric car at lowest price.\n",
      "\t-> car electric\n",
      "\t-> price lowest\n",
      "extract 7\n",
      "I want a cheap V-8 engine car.\n",
      "\t-> car cheap\n",
      "\t-> car V-8\n",
      "\t-> car engine\n",
      "extract 8\n",
      "I want a white car with rich technology.\n",
      "\t-> car white\n",
      "\t-> technology rich\n",
      "extract 9\n",
      "I want a diesel-driven car with high engine power.\n",
      "\t-> car diesel-driven\n",
      "\t-> power high\n",
      "\t-> power engine\n",
      "extract 10\n",
      "I want a small emission volume car with CarPlay.\n",
      "\t-> car small\n",
      "\t-> car volume\n",
      "extract 11\n",
      "I want a light-color 2018 Ford SUV.\n",
      "\t-> SUV light-color\n",
      "\t-> SUV Ford\n",
      "extract 12\n",
      "I want a red car with high safety configurations.\n",
      "\t-> car red\n",
      "\t-> configurations high\n",
      "\t-> configurations safety\n",
      "extract 13\n",
      "I want to keep warm in winter and start the car remotely.\n",
      "\t-> start remotely\n",
      "extract 14\n",
      "I am a student searching for a cost-effective car for school.\n",
      "\t-> car cost-effective\n",
      "extract 15\n",
      "I am a racecar lover with limited budget.\n",
      "\t-> budget limited\n",
      "extract 16\n",
      "I want a car with rich gear levels and high horse power.\n",
      "\t-> levels rich\n",
      "\t-> levels gear\n",
      "\t-> power high\n",
      "extract 17\n",
      "I want a white four-wheels-drive BMW sedan.\n",
      "\t-> sedan white\n",
      "\t-> sedan four-wheels-drive\n",
      "\t-> sedan BMW\n",
      "extract 18\n",
      "I am a new driver seeking for a moderate emission volume car with moderate price.\n",
      "\t-> car moderate\n",
      "\t-> car volume\n",
      "\t-> price moderate\n",
      "extract 19\n",
      "I want an SUV with good performance in snowy weather.\n",
      "\t-> performance good\n",
      "\t-> weather snowy\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f\"extract {i}\")\n",
    "    fe.extract(getq(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_trees = [\n",
    "    FeatureExtractor.build_tree(getq(i)) for i in range(20)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: keep, dep_: xcomp\n",
      "│   ├── text: to, dep_: aux\n",
      "│   ├── text: warm, dep_: oprd\n",
      "│   ├── text: in, dep_: prep\n",
      "│   │   └── text: winter, dep_: pobj\n",
      "│   ├── text: and, dep_: cc\n",
      "│   └── text: start, dep_: conj\n",
      "│       ├── text: car, dep_: dobj\n",
      "│       │   └── text: the, dep_: det\n",
      "│       └── text: remotely, dep_: advmod\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[13].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: a, dep_: det\n",
      "│   ├── text: red, dep_: amod\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: seats, dep_: pobj\n",
      "│           └── text: heated, dep_: amod\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[0].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: a, dep_: det\n",
      "│   ├── text: blue, dep_: amod\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: CarPlay, dep_: pobj\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[1].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: an, dep_: det\n",
      "│   ├── text: old, dep_: amod\n",
      "│   │   ├── text: and, dep_: cc\n",
      "│   │   └── text: cheap, dep_: conj\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: volume, dep_: pobj\n",
      "│           ├── text: emission, dep_: compound\n",
      "│           └── text: of, dep_: prep\n",
      "│               └── text: 3.0, dep_: pobj\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[2].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: an, dep_: det\n",
      "│   ├── text: expensive, dep_: amod\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: configurations, dep_: pobj\n",
      "│           └── text: all, dep_: det\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[3].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: a, dep_: det\n",
      "│   ├── text: black, dep_: amod\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: system, dep_: pobj\n",
      "│           ├── text: navigation, dep_: compound\n",
      "│           ├── text: and, dep_: cc\n",
      "│           └── text: price, dep_: conj\n",
      "│               └── text: moderate, dep_: amod\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[4].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: a, dep_: det\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: performance, dep_: pobj\n",
      "│           └── text: high, dep_: amod\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[5].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10529335708013777914, [4, 5, 7])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_matcher = DependencyMatcher(vocab=nlp.vocab)\n",
    "dep_pattern = [\n",
    "    {'RIGHT_ID': 'p_object', 'RIGHT_ATTRS': {'DEP': 'dobj'}},\n",
    "    {'LEFT_ID': 'p_object', 'REL_OP': '>', 'RIGHT_ID': 'p_prep_to_object', 'RIGHT_ATTRS': {'DEP': 'prep'}},\n",
    "    {'LEFT_ID': 'p_prep_to_object', 'REL_OP': '>', 'RIGHT_ID': 'p_prep_subject', 'RIGHT_ATTRS': {'DEP': {\"REGEX\": \"\\s*\"}}}\n",
    "]\n",
    "dep_matcher.add('object_descpt', patterns=[dep_pattern])\n",
    "dep_matches = dep_matcher(doc)\n",
    "dep_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want a black car with navigation system and moderate price.\n",
      "\tcar: <generator object at 0x7fc1d8c95cb0>\n"
     ]
    }
   ],
   "source": [
    "for match in dep_matches:\n",
    "    pattern_name = match[0]\n",
    "    matches = match[1]\n",
    "    p_object, p_prep_to_object, p_prep_subject = matches[0], matches[1], matches[2]\n",
    "    print(f\"{doc}\\n\\t{doc[p_object]}: {doc[p_prep_subject]}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1af9a45123dec21e89a2ab26916fe473fe7ed338517d03d80894fba70416b859"
  },
  "kernelspec": {
   "display_name": "OCaml default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
