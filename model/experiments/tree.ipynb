{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sense2vec.component.Sense2VecComponent at 0x7fde71ad53d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from treelib import Node, Tree\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span\n",
    "import pandas as pd\n",
    "from sense2vec import Sense2VecComponent\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "s2v = nlp.add_pipe(\"sense2vec\")\n",
    "s2v.from_disk(\"../../s2v_reddit_2019_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"x\": 1,\\n  \"y\": 2\\n}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'x': 1, 'y': 2}\n",
    "import json\n",
    "json.dumps(d, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I want a red car with heated seats.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I want a blue car with CarPlay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I want an old and cheap car with emission volu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I want an expensive car with all configurations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I want a black car with navigation system and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  0                I want a red car with heated seats.\n",
       "1  1                    I want a blue car with CarPlay.\n",
       "2  2  I want an old and cheap car with emission volu...\n",
       "3  3   I want an expensive car with all configurations.\n",
       "4  4  I want a black car with navigation system and ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df = pd.read_csv(\"../queries/query_20.tsv\", sep=\"\\t\", header=None)\n",
    "getq = lambda i: queries_df.loc[i, 1]\n",
    "queries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_infix_regex\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    inf = list(nlp.Defaults.infixes)               # Default infixes\n",
    "    inf.remove(r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\")    # Remove the generic op between numbers or between a number and a -\n",
    "    inf = tuple(inf)                               # Convert inf to tuple\n",
    "    infixes = inf + tuple([r\"(?<=[0-9])[+*^](?=[0-9-])\", r\"(?<=[0-9])-(?=-)\"])  # Add the removed rule after subtracting (?<=[0-9])-(?=[0-9]) pattern\n",
    "    infixes = [x for x in infixes if '-|–|—|--|---|——|~' not in x] # Remove - between letters rule\n",
    "    infix_re = compile_infix_regex(infixes)\n",
    "\n",
    "    return Tokenizer(nlp.vocab, prefix_search=nlp.tokenizer.prefix_search,\n",
    "                                suffix_search=nlp.tokenizer.suffix_search,\n",
    "                                infix_finditer=infix_re.finditer,\n",
    "                                token_match=nlp.tokenizer.token_match,\n",
    "                                rules=nlp.Defaults.tokenizer_exceptions)\n",
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.dep_matcher = DependencyMatcher(vocab=nlp.vocab)\n",
    "        main_patterns = [\n",
    "                # [\n",
    "                #     {'RIGHT_ID': 'p_subject', 'RIGHT_ATTRS': {'TEXT': 'car', 'DEP': 'dobj'}},\n",
    "                #     {'LEFT_ID': 'p_subject', 'REL_OP': '>', 'RIGHT_ID': 'p_prep_to_subject', 'RIGHT_ATTRS': {'DEP': 'prep'}},\n",
    "                #     {'LEFT_ID': 'p_prep_to_subject', 'REL_OP': '>', 'RIGHT_ID': 'p_prep_object', 'RIGHT_ATTRS': {'DEP': {\"REGEX\": \"\\s*\"}}}\n",
    "                # ],\n",
    "                [\n",
    "                {'RIGHT_ID': 'p_object', 'RIGHT_ATTRS': {'DEP': {\"IN\": ['dobj', 'pobj']}}},\n",
    "                {'LEFT_ID': 'p_object', 'REL_OP': '>', 'RIGHT_ID': 'p_object_mod', 'RIGHT_ATTRS': {'DEP': 'amod'}},\n",
    "                ]\n",
    "            ] # TODO: CONFIG HERE\n",
    "        self.dep_matcher.add(f\"main_patterns\", patterns=main_patterns)\n",
    "    \n",
    "    @staticmethod\n",
    "    def traverse(s, tree):\n",
    "        for c in s.children:\n",
    "            tree.create_node(c, c,  parent=s, data=c)\n",
    "            tree = FeatureExtractor.traverse(c, tree=tree)\n",
    "        return tree\n",
    "    \n",
    "    @staticmethod   \n",
    "    def build_tree(query):\n",
    "        doc = nlp(query)\n",
    "        sent_tree = Tree()\n",
    "        s = list(doc.sents)[0].root\n",
    "        sent_tree.create_node(s, s, data=s)\n",
    "        sent_tree = FeatureExtractor.traverse(s, sent_tree)\n",
    "        return sent_tree\n",
    "    \n",
    "    @staticmethod  \n",
    "    def build_tree_from_node(node):\n",
    "        sent_tree = Tree()\n",
    "        sent_tree.create_node(node, node, data=node)\n",
    "        sent_tree = FeatureExtractor.traverse(node, sent_tree)\n",
    "        return sent_tree\n",
    "    \n",
    "    @staticmethod\n",
    "    def compile_secondary_patterns(main_subject=\"\"):\n",
    "        secondary_patterns = [\n",
    "            [\n",
    "                {'RIGHT_ID': 'p_object', 'RIGHT_ATTRS': {'DEP': {\"IN\": ['dobj', 'pobj']}}},\n",
    "                {'LEFT_ID': 'p_object', 'REL_OP': '>', 'RIGHT_ID': 'p_object_mod', 'RIGHT_ATTRS': {'DEP': {\"IN\": ['amod', 'compound']}}},\n",
    "            ],\n",
    "            [\n",
    "                {'RIGHT_ID': 'p_conj', 'RIGHT_ATTRS': {'DEP': 'conj'}},\n",
    "                {'LEFT_ID': 'p_conj', 'REL_OP': '>', 'RIGHT_ID': 'p_conj_mod', 'RIGHT_ATTRS': {'DEP': {\"IN\": ['amod', 'advmod']}}},\n",
    "            ]\n",
    "        ]\n",
    "        return secondary_patterns\n",
    "    \n",
    "    def extract(self, query):\n",
    "        nlp.tokenizer = custom_tokenizer(nlp)\n",
    "        doc = nlp(query)\n",
    "        secondary_matcher = DependencyMatcher(vocab=nlp.vocab)\n",
    "        secondary_matcher.add(\"secondary_patterns\", FeatureExtractor.compile_secondary_patterns())\n",
    "        dep_matches = secondary_matcher(doc)\n",
    "        matches_str = []\n",
    "        for match in dep_matches:\n",
    "            matches = match[1]\n",
    "            p_1, p_2 = matches[0], matches[1]\n",
    "            # print(f\"\\t-> {doc[p_1]} {doc[p_2]}\")\n",
    "            matches_str.append(f\"{doc[p_2]} {doc[p_1]}\")\n",
    "        return matches_str        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6349"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from pathlib import Path\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(\"I want a blue car with strong horsepower.\")\n",
    "svg = displacy.render(doc, style=\"dep\", jupyter=False)\n",
    "file_name = \"dependency.svg\"\n",
    "output_path = Path(f\"{file_name}\")\n",
    "output_path.open(\"w\", encoding=\"utf-8\").write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red car', 'heated seats']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.extract(\"I want a red car with heated seats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red SUV', 'heated seats']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.extract(\"I want a red SUV with heated seats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black car', 'wind shield']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.extract(\"I want a black car with wind shield.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract 0\n",
      "['red car', 'heated seats']\n",
      "extract 1\n",
      "['blue car']\n",
      "extract 2\n",
      "['old car', 'emission volume']\n",
      "extract 3\n",
      "['expensive car']\n",
      "extract 4\n",
      "['black car', 'navigation system', 'moderate price']\n",
      "extract 5\n",
      "['high performance']\n",
      "extract 6\n",
      "['electric car', 'lowest price']\n",
      "extract 7\n",
      "['cheap car', 'V-8 car', 'engine car']\n",
      "extract 8\n",
      "['white car', 'rich technology']\n",
      "extract 9\n",
      "['diesel-driven car', 'high power', 'engine power']\n",
      "extract 10\n",
      "['small car', 'volume car']\n",
      "extract 11\n",
      "['Ford SUV']\n",
      "extract 12\n",
      "['red car', 'high configurations', 'safety configurations']\n",
      "extract 13\n",
      "['remotely start']\n",
      "extract 14\n",
      "['cost-effective car']\n",
      "extract 15\n",
      "['limited budget']\n",
      "extract 16\n",
      "['rich levels', 'gear levels', 'high power']\n",
      "extract 17\n",
      "['four-wheels-drive sedan', 'BMW sedan']\n",
      "extract 18\n",
      "['moderate car', 'volume car', 'moderate price']\n",
      "extract 19\n",
      "['good performance', 'snowy weather']\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(f\"extract {i}\")\n",
    "    print(fe.extract(getq(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white car\n",
      "[(('silver car', 'NOUN'), 0.9035), (('black car', 'NOUN'), 0.8969), (('cammer', 'NOUN'), 0.8732)]\n",
      "rich technology\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't find key rich_technology|NOUN in table",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ht/4wh6gs_11c336t4pd2t6bpph0000gp/T/ipykernel_7481/2580935136.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms2v_most_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/SI650/lib/python3.7/site-packages/sense2vec/component.py\u001b[0m in \u001b[0;36ms2v_most_similar\u001b[0;34m(self, obj, n)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \"\"\"\n\u001b[1;32m    206\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms2v_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_s2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SI650/lib/python3.7/site-packages/sense2vec/sense2vec.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, keys, n, batch_size)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Can't find key {key} in table\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"indices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't find key rich_technology|NOUN in table"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "for d in fe.extract(getq(i)):\n",
    "    print(d)\n",
    "    doc = nlp(d)\n",
    "    print(doc[0::]._.s2v_most_similar(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_trees = [\n",
    "    FeatureExtractor.build_tree(getq(i)) for i in range(20)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: keep, dep_: xcomp\n",
      "│   ├── text: to, dep_: aux\n",
      "│   ├── text: warm, dep_: acomp\n",
      "│   ├── text: in, dep_: prep\n",
      "│   │   └── text: winter, dep_: pobj\n",
      "│   ├── text: and, dep_: cc\n",
      "│   └── text: start, dep_: conj\n",
      "│       ├── text: car, dep_: dobj\n",
      "│       │   └── text: the, dep_: det\n",
      "│       └── text: remotely, dep_: advmod\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[13].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: a, dep_: det\n",
      "│   ├── text: red, dep_: amod\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: seats, dep_: pobj\n",
      "│           └── text: heated, dep_: amod\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[0].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: a, dep_: det\n",
      "│   ├── text: blue, dep_: amod\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: CarPlay, dep_: pobj\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[1].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: an, dep_: det\n",
      "│   ├── text: old, dep_: amod\n",
      "│   │   ├── text: and, dep_: cc\n",
      "│   │   └── text: cheap, dep_: conj\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: volume, dep_: pobj\n",
      "│           ├── text: emission, dep_: compound\n",
      "│           └── text: of, dep_: prep\n",
      "│               └── text: 3.0, dep_: pobj\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[2].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: an, dep_: det\n",
      "│   ├── text: expensive, dep_: amod\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: configurations, dep_: pobj\n",
      "│           └── text: all, dep_: det\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[3].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: a, dep_: det\n",
      "│   ├── text: black, dep_: amod\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: system, dep_: pobj\n",
      "│           ├── text: navigation, dep_: compound\n",
      "│           ├── text: and, dep_: cc\n",
      "│           └── text: price, dep_: conj\n",
      "│               └── text: moderate, dep_: amod\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[4].show(data_property=[\"text\", \"dep_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: want, dep_: ROOT\n",
      "├── text: I, dep_: nsubj\n",
      "├── text: car, dep_: dobj\n",
      "│   ├── text: a, dep_: det\n",
      "│   └── text: with, dep_: prep\n",
      "│       └── text: performance, dep_: pobj\n",
      "│           └── text: high, dep_: amod\n",
      "└── text: ., dep_: punct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent_trees[5].show(data_property=[\"text\", \"dep_\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1af9a45123dec21e89a2ab26916fe473fe7ed338517d03d80894fba70416b859"
  },
  "kernelspec": {
   "display_name": "OCaml default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
